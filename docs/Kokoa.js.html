<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: Kokoa.js</title>

    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">

    <h1 class="page-title">Source: Kokoa.js</h1>

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/* KokoaNLP
Copyright (C) 2018  Seungjae Park

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see &lt;http://www.gnu.org/licenses/>. */

const fs = require('fs');
const Hanguler = require('hanguler');

// Subtext extractor cache
const syllableRecipes = new Map();

/**
 * Extracts chunks from the given document.
 * @private
 * @param {string} document The document to extract subtexts.
 * @returns {Array.&lt;string>} Subtexts of the document.
 */
const extractChunks = (document) => {
  const alphabetRegex = /^[A-z]+$/;
  const hangulRegex = /^[가-힣]+$/;
  const numberRegex = /^[0-9]+$/;
  const chunks = [];
  document.split('').forEach((char) => {
    const previousChunk = chunks[chunks.length - 1] || '';
    if ((alphabetRegex.test(previousChunk) &amp;&amp; alphabetRegex.test(char)) // if char is alphabet
      || (hangulRegex.test(previousChunk) &amp;&amp; hangulRegex.test(char)) // if char is hangul
      || (numberRegex.test(previousChunk) &amp;&amp; numberRegex.test(char)) // if char is number
      || (previousChunk[previousChunk.length - 1] === char)) { // if char is repeated
      chunks[chunks.length - 1] += char;
    } else {
      chunks.push(char);
    }
  });
  return chunks;
};

/**
 * Extracts subtexts and their complements from the given chunk.
 * @private
 * @param {string} chunk The document to extract chunks.
 * @returns {Array.&lt;string>} Chunks of the document.
 */
const extractSubtexts = (chunk) => {
  if (syllableRecipes.has(chunk)) {
    return syllableRecipes.get(chunk);
  }
  const subtexts = [];
  const chars = Hanguler.flatDisassemble(chunk);
  for (let i = 1, len = chars.length; i &lt;= len; i += 1) {
    const subtext = Hanguler.flatAssemble(chars.slice(0, i));
    if (!Hanguler.isConsonant(subtext[subtext.length - 1])) {
      const others = chars.slice(i);
      if (others.length >= 1) {
        if (Hanguler.isVowel(others[0])) {
          others.unshift('ㅇ');
        }
        subtexts.push([subtext, Hanguler.flatAssemble(others)]);
      } else {
        subtexts.push([subtext, '']);
      }
    }
  }
  syllableRecipes.set(chunk, subtexts);
  return subtexts;
};

/**
 * Class representing KokoaNLP.
 */
class Kokoa {
  /**
   * Creates KokoaNLP instance.
   * @param {Array.&lt;Array.&lt;string|number>>} [wordFrequencies] How many times words appear.
   * @param {Array.&lt;Array.&lt;string|number>>} [wordScores] Words cohension n-gram value.
   */
  constructor(lFrequencies, rFrequencies, lScores, rScores) {
    this.lFrequencies = new Map(lFrequencies);
    this.rFrequencies = new Map(rFrequencies);
    this.lScores = new Map(lScores);
    this.rScores = new Map(rScores);
  }

  /**
   * Loads KokoaNLP instance from the given model.
   * @param {string} file KokoaNLP model file path.
   * @returns {Kokoa} KokoaNLP instance.
   */
  static loadFile(file) {
    if (fs.exists(file)) {
      const content = fs.readFileSync(file).split('\n').map(value => value.split(','));
      const lFrequencies = content.map(value => [value[0], Number(value[1])]);
      const rFrequencies = content.map(value => [value[0], Number(value[2])]);
      const lScores = content.map(value => [value[0], Number(value[3])]);
      const rScores = content.map(value => [value[0], Number(value[4])]);
      return new Kokoa(lFrequencies, rFrequencies, lScores, rScores);
    }
    return null;
  }

  /**
   * Document analyzer options
   * @typedef {Object} KokoaOptions
   * @property {boolean} [hangulOnly=true] If true, only returns hangul contents.
   * @property {number} [minCount=5] Ignores all words with total frequency lower than this.
   */

  /**
   * Analyzes the given document.
   * @param {string} document The document to be analyzed.
   * @param {KokoaOptions} [options] Document analyzer options
   * @returns {Array.&lt;string>} Words of the document.
   */
  run(document, { hangulOnly = true, minCount = 5 } = {}) {
    const { lFrequencies, lScores, rScores } = this;
    const chunks = extractChunks(document);
    const words = [];
    chunks.forEach((chunk) => {
      if (Hanguler.isHangul(chunk)) {
        const subtexts = extractSubtexts(chunk);
        console.log(subtexts);
        const word = subtexts
          .map(([subtext, complement]) => [
            subtext,
            (lScores.has(subtext) ? lScores.get(subtext) : 0.01)
            * (rScores.has(complement) ? rScores.get(complement) : 0.01),
          ])
          .reduce((r, a) => (a[1] > r[1] ? a : r))[0];
        if (lFrequencies.get(word) >= minCount) {
          words.push(word);
        }
      } else if (!hangulOnly) {
        words.push(chunk);
      }
    });
    return words;
  }

  /**
   * Saves KokoaNLP instance as a file.
   * @param {string} file KokoaNLP model file path.
   */
  // saveFile(file) {
  //   const { lFrequencies, lScores, rFrequencies, rScores } = this;
  //   const content = lFrequencies.entries()
  //     .map(([l, lFrequency]) => [l, lFrequency, lScores.get(l)].join(','))
  //     .join('\n');
  //   fs.writeFileSync(file, content);
  // }

  /**
   * Trains the given document.
   * @param {string} document The document to be trained.
   */
  train(document) {
    const { lFrequencies, rFrequencies } = this;
    const chunks = extractChunks(document).filter(Hanguler.isHangul).map(extractSubtexts);
    // Extract all words and count how many words appear.
    for (let i = 0, len = chunks.length; i &lt; len; i += 1) {
      const subtexts = chunks[i];
      for (let j = 0, len2 = subtexts.length; j &lt; len2; j += 1) {
        const subtext = subtexts[j];
        if (lFrequencies.has(subtext)) {
          lFrequencies.set(subtext, lFrequencies.get(subtext) + 1);
        } else {
          lFrequencies.set(subtext, 1);
        }
        if (rFrequencies.has(subtext)) {
          rFrequencies.set(subtext, rFrequencies.get(subtext) + 1);
        } else {
          rFrequencies.set(subtext, 1);
        }
      }
    }
  }

  /** Updates calculated cohension n-gram value for each word. */
  update() {
    const {
      lFrequencies, lScores, rFrequencies, rScores,
    } = this;
    lFrequencies.forEach((frequency, subtext, frequencies) => {
      if (subtext.length === 1) {
        lScores.set(subtext, 0.1);
      } else {
        const exp = 1 / Hanguler.flatDisassemble(subtext).length;
        lScores.set(subtext, (frequency / frequencies.get(subtext[0])) ** exp);
      }
    });
    rFrequencies.forEach((frequency, subtext, frequencies) => {
      if (subtext.length === 1) {
        rScores.set(subtext, 0.1);
      } else {
        const exp = 1 / Hanguler.flatDisassemble(subtext).length;
        rScores.set(subtext, (frequency / frequencies.get(subtext[0])) ** exp);
      }
    });
  }
}

module.exports = Kokoa;
</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Home</a></h2><h3>Classes</h3><ul><li><a href="Kokoa.html">Kokoa</a></li><li><a href="KokoaUtil.html">KokoaUtil</a></li></ul><h3><a href="global.html">Global</a></h3>
</nav>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.5.5</a> on Wed Jun 06 2018 23:37:02 GMT+0900 (KST)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
